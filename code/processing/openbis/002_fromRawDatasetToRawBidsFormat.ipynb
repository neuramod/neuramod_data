{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENBIS\n",
    "from pybis import Openbis\n",
    "o = Openbis()\n",
    "# Use this code to reconnect in case your openBIS session expires and you an error on the previous step.\n",
    "sessionToken = \"nqureshi-230202111003902x7B315CC0D30C1CD2D2324FDAF105573C\"\n",
    "o.set_token(token=sessionToken)\n",
    "\n",
    "# INSTALL ADDITIONAL PACKAGES\n",
    "!pip install --index-url https://nexus-central.leomed.ethz.ch/repository/pypi/simple mne\n",
    "!pip install --index-url https://nexus-central.leomed.ethz.ch/repository/pypi/simple mne_bids\n",
    "!pip install --index-url https://nexus-central.leomed.ethz.ch/repository/pypi/simple pybv==0.6.0\n",
    "!pip install --index-url https://nexus-central.leomed.ethz.ch/repository/pypi/simple openpyxl\n",
    "    \n",
    "# INFOS\n",
    "# RESTART THE SERVER IF THE FOLLOWING ERROR OCCURS\n",
    "#    ValueError: events: when `type` is Stimulus, descriptions must be positve ints.\n",
    "#OR\n",
    "#    IndexError: list index out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55234114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN PARAMS\n",
    "\n",
    "raw_modes = ['BLED','LSLD'] # these recording modes will transformed into BIDS datasets\n",
    "bids_path = './BIDS' # local path for temporary downloads\n",
    "\n",
    "# METHODS\n",
    "def data_slicing(save_path,photodiode_file, eeg_file, photodiode_cutoff, participant_id, project_phase, session_id, task_name):\n",
    "    \"\"\" Return sliced EEG file for respective task \"\"\"\n",
    "    df_slice = pd.read_csv(photodiode_file)\n",
    "    df_slice['f'] = df_slice['Photodiode-ch1'].astype(str).str[:2].astype(int)\n",
    "    # Extracting peak value \n",
    "    peak_value = df_slice[df_slice.f >= photodiode_cutoff]   # peak value depend on visual inspection of photodiode\n",
    "    peak_value.reset_index(level=0, inplace=True)\n",
    "    value = peak_value.iloc[0, 0]\n",
    "    initial_corrected_data = df_slice.iloc[value:,0:5]\n",
    "    df_raw = pd.read_csv(eeg_file)\n",
    "    result_EEG = df_raw.iloc[value:,:]\n",
    "    result_EEG.to_csv(os.path.join(save_path, f\"{participant_id}_{project_phase}_{session_id}_{task_name}.csv\"), index = False)\n",
    "    \n",
    "\n",
    "\n",
    "def event_sequence(rest_time, rest_time_trial, stimulus_display, stimuli_number, event_start, datapoints_start,trial_length, sampling_frequency, data = []):\n",
    "    \"\"\"Return a sequence of events from a stimulation file.\"\"\"\n",
    "    \n",
    "    # DEBUG\n",
    "    #for i in range(event_start,trial_length + 1, math.floor(sampling_frequency/2)):\n",
    "    #\n",
    "    for i in range(event_start,trial_length + 1, math.ceil(sampling_frequency*stimulus_display)):\n",
    "        data.append(i)\n",
    "        \n",
    "    sequence = pd.DataFrame(data)\n",
    "    m = sequence.iloc[-1,:]\n",
    "    #next_trial_rest = int((rest_time * sampling_frequency) + m)\n",
    "    next_trial_rest = int((rest_time_trial  * sampling_frequency) + m)\n",
    "    #next_trial_length = int(next_trial_rest + (stimulus_display * sampling_frequency * stimuli_number))\n",
    "    next_trial_length = int(next_trial_rest + (stimulus_display * sampling_frequency * datapoints_start))\n",
    "    \n",
    "    return data, next_trial_rest, next_trial_length\n",
    "def createBaseBidsFile(the_slice_eeg_file, layout_file, events_file, base_path = '.', unit = 'µV', sampling_frequency = 256, standard_montage = 'standard_1020', authors = ['',], funding = ''):\n",
    "    \"\"\"Create the base structure and files for Bids standards without additional infos.\"\"\"\n",
    "\n",
    "    df = pd.read_csv(the_slice_eeg_file)\n",
    "    layout_raw = pd.read_excel(layout_file,index_col = 0)\n",
    "    df_mne = df.drop(['timestamp', 'sequence', 'battery', 'flags'], axis=1)# based on bitbrain file format\n",
    "    # change after Phase 1\n",
    "    #df_mne[\"EEG\"]=df_mne['EEG_ch1']\n",
    "    df_mne[\"EEG\"]=df_mne['EEG-ch1']\n",
    "    #\n",
    "    ch_names = []\n",
    "    \n",
    "    #eeg_cols = [col for col in df.columns if 'EEG' in col]\n",
    "    eeg_cols = [col for col in df_mne.columns if 'EEG' in col]\n",
    "\n",
    "    for i in range(len(eeg_cols)):\n",
    "        the_name = layout_raw.index[layout_raw['Channel number'] == i+1].tolist()[0].replace('0','O')\n",
    "        ch_names.append(the_name)\n",
    "\n",
    "    data = df_mne.to_numpy().transpose()\n",
    "    data = np.vstack(data/10e5) if unit == 'µV' else None\n",
    "    #unit = [unit] * len(eeg_cols)\n",
    "    unit = [unit] * len(eeg_cols)\n",
    "    print(f\"DEBUG eeg_cols: {len(eeg_cols)}\")\n",
    "    event = pd.read_csv(events_file)\n",
    "    events = np.asarray(event)\n",
    "\n",
    "    code = f\"{events_dict['participant_id']}_{events_dict['project_phase']}_{events_dict['session_id']}_{events_dict['task_name']}\"\n",
    "    pybv.write_brainvision(data = data, \n",
    "                           sfreq = float(sampling_frequency), \n",
    "                           ch_names = ch_names,\n",
    "                           folder_out = os.path.join(base_path,f\"{code}\"),\n",
    "                           fname_base = code, \n",
    "                           events = events,\n",
    "                           unit = unit,\n",
    "                           overwrite = True)\n",
    "    # change after Phase 1\n",
    "    #raw = mne.io.read_raw_brainvision(os.path.join(base_path,code,f\"{code}.vhdr\"), preload=False)\n",
    "    raw = mne.io.read_raw_brainvision(os.path.join(base_path,code,f\"{code}.vhdr\"), preload=False)\n",
    "    raw.set_channel_types(mapping={'EOG': 'eeg'})\n",
    "    raw.rename_channels(mapping={'EOG': 'EOG'})\n",
    "    raw.set_channel_types(mapping={'EOG': 'eog'})\n",
    "    #\n",
    "    montage = mne.channels.make_standard_montage(standard_montage)\n",
    "    raw = raw.copy().set_montage(montage)\n",
    "    raw.set_montage(montage)\n",
    "    print(raw.annotations)\n",
    "    print(write_raw_bids.__doc__)\n",
    "    \n",
    "    bids_path = BIDSPath(subject = events_dict['participant_id'],\n",
    "                         task = events_dict['task_name'],\n",
    "                         root = os.path.join(base_path,code,code)\n",
    "                         )\n",
    "    write_raw_bids(raw, bids_path, overwrite = True)\n",
    "    print(f\"DEBUG path: {os.path.join(base_path,code,code)}\")\n",
    "    print(f\"DEBUG path: {code}\")\n",
    "    make_dataset_description(path=os.path.join(base_path,code,code), \n",
    "                             name=code, \n",
    "                             authors = authors, \n",
    "                             funding = funding, \n",
    "                             overwrite = True)\n",
    "    \n",
    "    return os.path.join(base_path,f\"{code}\")\n",
    "#\n",
    "def updateBidsInfos(subject = None, task = None, suffix = None, datatype = None, root = None, extension = '.json', entries_dict = {}):\n",
    "    \"\"\"Add additional informations to a bids data folder.\"\"\"\n",
    "    \n",
    "    bids_path = BIDSPath(subject = subject,\n",
    "                         task = task, \n",
    "                         suffix = suffix,\n",
    "                         datatype = datatype, \n",
    "                         root = root\n",
    "                        )                                         \n",
    "    sidecar_path = bids_path.copy().update(extension = extension)\n",
    "    entries = entries_dict\n",
    "    update_sidecar_json(bids_path = sidecar_path, \n",
    "                        entries = entries)\n",
    "#\n",
    "def updateBidsChannels(the_path, the_id, the_task, hi = 'n/a', lo = 'n/a', desc = 'EEG'):\n",
    "    \"\"\"Overwrite a Bids channel file with missing basic infos.\"\"\"\n",
    "    \n",
    "    fname = os.path.join(the_path, f\"sub-{the_id}\", f\"{desc.lower()}\", f\"sub-{the_id}_task-{the_task}_channels.tsv\")\n",
    "    df = pd.read_csv(fname, sep=\"\\t\")\n",
    "    df[\"low_cutoff\"] = lo\n",
    "    df[\"high_cutoff\"] = hi\n",
    "    df[\"description\"] = desc\n",
    "    df.to_csv(fname, \n",
    "              index = False, \n",
    "              sep = \"\\t\",\n",
    "              na_rep = \"n/a\")\n",
    "    #\n",
    "def updateBidsParticipants(the_path, participant_dict):\n",
    "    \"\"\"Overwrite a Bids participants file with missing basic infos.\"\"\"\n",
    "    \n",
    "    fname = os.path.join(the_path, \"participants.tsv\")\n",
    "    df = pd.read_csv(fname, \n",
    "                     sep = \"\\t\")\n",
    "    for _k in participant_dict:\n",
    "        df[_k] = participant_dict[_k]\n",
    "    df.to_csv(fname, \n",
    "              index = False, \n",
    "              sep = \"\\t\", \n",
    "              na_rep = \"n/a\")\n",
    "    \n",
    "#\n",
    "def readSamplingFrequencyFromRawData(json_file, signal_name):\n",
    "    \"\"\"Read a Json File and return its indicated sampling frequency for a given signal name.\n",
    "       Based on BitBrain file formats.\n",
    "    \"\"\"\n",
    "    \n",
    "    sampling_frequency = None\n",
    "    \n",
    "    with open(json_file) as jf:\n",
    "        info = json.load(jf)\n",
    "        for _signal in info['signals']:\n",
    "            if signal_name in _signal['filename']:\n",
    "                sampling_frequency = int(_signal['sampling_rate'])\n",
    "    \n",
    "    return sampling_frequency\n",
    "#\n",
    "def createEvents(save_path, data_csv_file, old_label, trial_number,rest_time_trial, sampling_frequency, trial_start, stimulus_display, datapoints_start, rest_time, stimuli_number, participant_id, project_phase, session_id, task_name):\n",
    "    \"\"\"Create events file for a task from a stimulation file.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_csv_file)\n",
    "    df.rename(columns = {f'{old_label}':'event_label'}, inplace = True)\n",
    "    event_label = df['event_label']\n",
    "    event_label.dropna(inplace=True)\n",
    "    event_label = event_label.astype('int')\n",
    "    event_start = int(sampling_frequency * trial_start)\n",
    "    #trial_length = int(stimulus_display * sampling_frequency * datapoints_start)\n",
    "    trial_length = int(event_start+stimulus_display * sampling_frequency * datapoints_start)\n",
    "    #trial_rest = trial_length + int(rest_time * sampling_frequency)\n",
    "    trial_rest = event_start\n",
    "    events = event_label.to_frame()\n",
    "    x = []\n",
    "    \n",
    "    # DEBUG\n",
    "    print(f\"DEBUG first event_start: {event_start}\")\n",
    "    rest_time = event_start\n",
    "    #\n",
    "    \n",
    "    for _t in range(trial_number):\n",
    "        x,event_start,trial_length = event_sequence(rest_time = rest_time, \n",
    "                                                    rest_time_trial=rest_time_trial,\n",
    "                                                    stimulus_display = stimulus_display, \n",
    "                                                    stimuli_number = stimuli_number, \n",
    "                                                    datapoints_start=datapoints_start,\n",
    "                                                    event_start = event_start, \n",
    "                                                    trial_length = trial_length, \n",
    "                                                    sampling_frequency = sampling_frequency, \n",
    "                                                    data = x)\n",
    "    # DEBUG\n",
    "    \n",
    "    print(f\"DEBUG trial rest: {trial_rest}\")\n",
    "    #print(f\"DEBUG x len: {len(x)}\")\n",
    "    #print(f\"DEBUG events size: {events.size}\")\n",
    "    #print(f\"DEBUG trial_number: {trial_number}\")\n",
    "    #print(f\"DEBUG datapoints_start: {datapoints_start}\")\n",
    "    #print(f\"DEBUG rest_time: {rest_time}\")\n",
    "    #print(f\"DEBUG stimulus_display: {stimulus_display}\")\n",
    "    #print(f\"DEBUG stimuli_number: {stimuli_number}\")\n",
    "    print(f\"DEBUG event_start: {event_start}\")\n",
    "    print(f\"DEBUG trial_length: {trial_length}\")\n",
    "    #print(f\"DEBUG sampling_frequency: {sampling_frequency}\")\n",
    "    #\n",
    "    \n",
    "    events['event_sequence'] = x\n",
    "    events = events[['event_sequence', 'event_label']]\n",
    "    events['trial'] = \"\"\n",
    "    #events['trial'] = [i for i in range(1, trial_number + 1) for j in range(stimuli_number + 1)]\n",
    "    events['trial'] = [i for i in range(1, trial_number + 1) for j in range(datapoints_start)]\n",
    "    events.to_csv(os.path.join(save_path, f\"{participant_id}_{project_phase}_{session_id}_{task_name}_events.csv\"), index = False)\n",
    "#\n",
    "def createReadme(path,data_dict):\n",
    "    \"\"\"Create a readme file in the json format at given path and with given dict.\"\"\"\n",
    "    \n",
    "    readme_path = os.path.join(path,\"README.json\")\n",
    "    temp = {}\n",
    "    \n",
    "    with open(readme_path, \"w\") as outfile:\n",
    "        # simplify subkeys to their attribute name\n",
    "        for _k in data_dict:\n",
    "            temp[_k] = {}\n",
    "            for _subk in data_dict[_k]:\n",
    "                the_val = data_dict[_k][_subk]\n",
    "                    \n",
    "                if '.' in _subk:\n",
    "                    temp[_k][_subk.split('.')[1]] = the_val.split('<body><p>')[1].split('</p></body>')[0] if '<body><p>' in f\"{the_val}\" else the_val\n",
    "                \n",
    "                else:\n",
    "                    #temp[_k][_subk.split[1]] = data_dict[_k][_subk]\n",
    "                    temp[_k][_subk] =  the_val.split('<body><p>')[1].split('</p></body>')[0] if '<body><p>' in f\"{the_val}\" else the_val\n",
    "           \n",
    "        json.dump(temp, outfile, indent = 4)\n",
    "        print(f\"-- temp: {temp}\")\n",
    "        #json.dump(data_dict, outfile)\n",
    "    \n",
    "    return readme_path\n",
    "#\n",
    "def createBidsFiles(events_dict,the_participant):\n",
    "    \"\"\"Create events, raw data slicing, brainvision and bids files and return their list\"\"\"\n",
    "    \n",
    "    list_of_files = []\n",
    "    the_participant = o.get_object(the_participant)\n",
    "    \n",
    "    # DEBUG\n",
    "    print(f\"- stim_infos: {events_dict['stim_infos']}\")\n",
    "    print(f\"- stim.rep_time: {int(events_dict['stim_infos']['stim.rep_time'])}\")\n",
    "    print(f\"- stim.num: {int(events_dict['stim_infos']['stim.num'])}\")\n",
    "    print(f\"- stim.rest_time: {events_dict['stim_infos']['stim.rest_time']}\")\n",
    "    print(f\"- stim.photodiode_cutoff: {int(events_dict['stim_infos']['stim.photodiode'])}\")\n",
    "    # Data slicing\n",
    "    data_slicing(save_path = events_dict['save_path'], photodiode_file=events_dict['photodiode_file'], \n",
    "                 eeg_file=events_dict['raw_eeg_file'],\n",
    "                 photodiode_cutoff = int(events_dict['stim_infos']['stim.photodiode']),\n",
    "                 participant_id = events_dict['participant_id'], \n",
    "                 project_phase = events_dict['project_phase'], \n",
    "                 session_id = events_dict['session_id'],\n",
    "                 task_name = events_dict['stim_infos']['stim.name']\n",
    "                )\n",
    "    the_slice_eeg_file = os.path.join(events_dict['save_path'], f\"{events_dict['participant_id']}_{events_dict['project_phase']}_{events_dict['session_id']}_{ events_dict['stim_infos']['stim.name']}.csv\")\n",
    "    list_of_files.append(the_slice_eeg_file)\n",
    "    \n",
    "    # create an event file by task\n",
    "    createEvents(save_path = events_dict['save_path'], \n",
    "                 data_csv_file = events_dict['stim_csv_file'],\n",
    "                 \n",
    "                 #old_label = events_dict['old_label'],\n",
    "                 old_label = events_dict['stim_infos']['stim.label_name'],\n",
    "                 \n",
    "                 #trial_number = events_dict['trial_number'],\n",
    "                 trial_number = int(events_dict['stim_infos']['stim.trials_number']),\n",
    "                 \n",
    "                 #sampling_frequency = events_dict['sampling_frequency'],\n",
    "                 sampling_frequency = int(events_dict['acquisition_infos']['sensor.sampling_frequency']),\n",
    "                 \n",
    "                 #trial_start = events_dict['trial_start'],\n",
    "                 trial_start = float(events_dict['stim_infos']['stim.trial_start']),\n",
    "                 \n",
    "                 #stimulus_display = events_dict['stimulus_display'],\n",
    "                 stimulus_display = float(events_dict['stim_infos']['stim.display_time']) + float(events_dict['stim_infos']['stim.notdisplay_time']),\n",
    "                 \n",
    "                 #datapoints_start = events_dict['datapoints_start'],\n",
    "                 datapoints_start = int(events_dict['stim_infos']['stim.datapoints_start']),\n",
    "                 \n",
    "                 #rest_time = events_dict['rest_time'],\n",
    "                 rest_time = float(events_dict['stim_infos']['stim.rest_time']),\n",
    "                 rest_time_trial = float(events_dict['stim_infos']['stim.rest_time']),\n",
    "                 \n",
    "                 #stimuli_number = events_dict['stimuli_number'],\n",
    "                 stimuli_number = int(events_dict['stim_infos']['stim.rep_time']) * int(events_dict['stim_infos']['stim.num']) - 1,\n",
    "                 \n",
    "                 participant_id = events_dict['participant_id'], \n",
    "                 project_phase = events_dict['project_phase'], \n",
    "                 session_id = events_dict['session_id'], \n",
    "                 \n",
    "                 #task_name = events_dict['task_name'],\n",
    "                 task_name = events_dict['stim_infos']['stim.name']\n",
    "                )\n",
    "    the_events_file = os.path.join(events_dict['save_path'], f\"{events_dict['participant_id']}_{events_dict['project_phase']}_{events_dict['session_id']}_{ events_dict['stim_infos']['stim.name']}_events.csv\")\n",
    "    list_of_files.append(the_events_file)\n",
    "    # create a base bids file\n",
    "    bids_root = createBaseBidsFile(#eeg_file = events_dict['raw_eeg_file'], \n",
    "                                   the_slice_eeg_file = the_slice_eeg_file,\n",
    "                                   layout_file = events_dict['eeg_layout_file'],\n",
    "                                   events_file = the_events_file,\n",
    "                                   base_path = events_dict['save_path'], \n",
    "                                   unit = events_dict['acquisition_infos']['sensor.units'],\n",
    "                                   sampling_frequency = events_dict['acquisition_infos']['sensor.sampling_frequency'], \n",
    "                                   standard_montage = events_dict['acquisition_infos']['sensor.layout'],\n",
    "                                   authors = events_dict['project_infos']['proj.authors'].split(','), \n",
    "                                   funding = events_dict['project_infos']['proj.funding']\n",
    "                                  )\n",
    "    sub_path = f\"{events_dict['participant_id']}_{events_dict['project_phase']}_{events_dict['session_id']}_{ events_dict['stim_infos']['stim.name']}\"\n",
    "    sub_root = os.path.join(f\"{bids_root}\",sub_path)\n",
    "    \n",
    "    # update eeg info\n",
    "    updateBidsInfos(subject = events_dict['participant_id'], \n",
    "                    task = events_dict['stim_infos']['stim.name'], \n",
    "                    suffix = events_dict['acquisition_infos']['sensor.modality'].lower()[:-1], \n",
    "                    datatype = events_dict['acquisition_infos']['sensor.modality'].lower()[:-1], \n",
    "                    root = sub_root, \n",
    "                    extension = '.json', \n",
    "                    entries_dict = events_dict['acquisition_infos'],\n",
    "                   )\n",
    "    # update participant infos\n",
    "    print(f\"DEBUG the_participant.props(): {the_participant.props()}\")\n",
    "\n",
    "    temp_participant = {}\n",
    "    for _k in the_participant.props():\n",
    "        if 'participant.id' in _k:\n",
    "            #temp_participant['participant_id'] = {the_participant.props()[_k],dict(\"Description\":\"\",\"Levels\":\"\")}\n",
    "            #temp_participant['participant_id'] = {the_participant.props()[_k],{\"Description\":\"\",\"Levels\":\"\"}}\n",
    "            temp_participant['participant_id'] = the_participant.props()[_k]\n",
    "        elif '.' in _k:\n",
    "            #temp_participant[_k.split('.')[1]] = {the_participant.props()[_k],{\"Description\":\"\",\"Levels\":\"\"}}\n",
    "            temp_participant[_k.split('.')[1]] = the_participant.props()[_k]\n",
    "            \n",
    "        else:\n",
    "            #temp_participant[_k] = {the_participant.props(),{\"Description\":\"\",\"Levels\":\"\"}}\n",
    "            temp_participant[_k] = the_participant.props()[_k]\n",
    "        \n",
    "    \n",
    "    updateBidsInfos(subject = None, \n",
    "                    task = None, \n",
    "                    suffix = 'participants', \n",
    "                    datatype = None, \n",
    "                    root = sub_root, \n",
    "                    extension = '.json', \n",
    "                    entries_dict = temp_participant, #the_participant.props(),\n",
    "                   )\n",
    "    #update channels infos\n",
    "    updateBidsChannels(the_path = sub_root,\n",
    "                       the_id = events_dict['participant_id'], \n",
    "                       the_task = events_dict['stim_infos']['stim.name'], \n",
    "                       hi = events_dict['acquisition_infos']['sensor.high_pass'], \n",
    "                       lo = events_dict['acquisition_infos']['sensor.low_pass'], \n",
    "                       desc = events_dict['acquisition_infos']['sensor.modality'].lower()[:-1]\n",
    "                      )\n",
    "    #update participants infos\n",
    "    updateBidsParticipants(the_path = sub_root,\n",
    "                           participant_dict = the_participant.props()\n",
    "                          )\n",
    "    #create a general description readme file\n",
    "    createReadme(sub_root,{'project':events_dict['project_infos'],\n",
    "                            'sensors':events_dict['acquisition_infos'],\n",
    "                            'stimulation':events_dict['stim_infos']})\n",
    "                               \n",
    "    #zip bids folder\n",
    "    #zip_path = os.path.join(sub_root,sub_path)\n",
    "    zip_path = sub_root\n",
    "        #zip bids folder\n",
    "    #zip_path = os.path.join(sub_root,sub_path)\n",
    "    zip_path = sub_root\n",
    "    \n",
    "    with ZipFile(f\"{zip_path}.zip\", mode='w') as zipf:\n",
    "        len_dir_path = len(zip_path)\n",
    "        for root, _, files in os.walk(zip_path):\n",
    "            for file in files:\n",
    "                if \".zip\" not in file:\n",
    "                    # rename old Readme file with Bids authors to a reference file\n",
    "                    if 'README' in file and '.json' not in file:\n",
    "                        old_path = os.path.join(root, file)\n",
    "                        new_path = os.path.join(root,'references.txt')\n",
    "                        os.rename(old_path,new_path)\n",
    "                        file_path = new_path\n",
    "                    elif 'references.txt' not in file:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                    else:\n",
    "                        continue\n",
    "                    zipf.write(file_path, file_path[len_dir_path:])\n",
    "                \n",
    "    list_of_files.append(f\"{zip_path}.zip\")\n",
    "    list_of_files.append(f\"{sub_root}.eeg\")\n",
    "    list_of_files.append(f\"{sub_root}.vhdr\")\n",
    "    list_of_files.append(f\"{sub_root}.vmrk\")\n",
    "    \n",
    "    return list_of_files\n",
    "#\n",
    "def createBidsDataset(the_bids_sample,bids_files,events_dict):\n",
    "    \"\"\"Create and save a new dataset from a parent sample and given files\"\"\"\n",
    "    \n",
    "    # create dataset for bids files\n",
    "    the_dset = o.new_dataset(type = 'RAWD_BIDS', \n",
    "                             sample = the_bids_sample,\n",
    "                             files = bids_files,\n",
    "                             props = {f'rawd_bids.name':events_dict['task_name'],\n",
    "                                      f'rawd_bids.session': events_dict['session_id'],\n",
    "                                      f'rawd_bids.phase': events_dict['project_phase'],\n",
    "                                      f'rawd_bids.participant': the_bids_sample.props('data_recording_mode.participant'),\n",
    "                                     },\n",
    "                            )\n",
    "    the_dset.save()\n",
    "#\n",
    "def getRawFilesAndData(raw_sample,the_stim_sample,download_path):\n",
    "    \"\"\"Get raw and stim files from database and download them locally.\"\"\"\n",
    "    \n",
    "    files_data = {}\n",
    "    \n",
    "    # get raw datasets to format\n",
    "    _datasets_raw = raw_sample.get_datasets()[0] # there should be only one dataset per session\n",
    "    _datasets_stim = the_stim_sample.get_datasets()[0] # idem\n",
    "\n",
    "    print('_datasets_raw.file_list: ',_datasets_raw.file_list)\n",
    "    _raw_signal = [_f for _f in _datasets_raw.file_list if '.json' in _f][0]\n",
    "    _raw_eeg = [_f for _f in _datasets_raw.file_list if 'EEG.csv' in _f][0]\n",
    "    _raw_eeg_layout = [_f for _f in _datasets_raw.file_list if 'Layout' in _f][0]\n",
    "    _raw_photodiode = [_f for _f in _datasets_raw.file_list if 'Photodiode.csv' in _f][0]\n",
    "    _raw_stim = [_f for _f in _datasets_stim.file_list if '.csv' in _f][0]\n",
    "    \n",
    "    # download locally the json,data file and read\n",
    "    _datasets_raw.download(f\"{_raw_signal}\",download_path)\n",
    "    _datasets_raw.download(f\"{_raw_eeg}\",download_path)\n",
    "    _datasets_raw.download(f\"{_raw_eeg_layout}\",download_path)\n",
    "    _datasets_raw.download(f\"{_raw_photodiode}\",download_path)\n",
    "    _datasets_stim.download(f\"{_raw_stim}\",download_path)\n",
    "    \n",
    "    signal_info_file = f\"{download_path}/{_datasets_raw.code}/original/DEFAULT/{_raw_signal.split('/')[-1]}\"\n",
    "    signal_info = readSamplingFrequencyFromRawData(signal_info_file, 'EEG')\n",
    "    stim_file = f\"{download_path}/{_datasets_stim.code}/original/DEFAULT/{_raw_stim.split('/')[-1]}\"\n",
    "    eeg_file = f\"{download_path}/{_datasets_raw.code}/original/DEFAULT/{_raw_eeg.split('/')[-1]}\"\n",
    "    photodiode_file = f\"{download_path}/{_datasets_raw.code}/original/DEFAULT/{_raw_photodiode.split('/')[-1]}\"\n",
    "    eeg_layout = f\"{download_path}/{_datasets_raw.code}/original/DEFAULT/{_raw_eeg_layout.split('/')[-1]}\"\n",
    "    \n",
    "    files_data['sampling_frequency'] = signal_info\n",
    "    files_data['stim_file'] = stim_file\n",
    "    files_data['eeg_file'] = eeg_file\n",
    "    files_data['photodiode_file'] = photodiode_file\n",
    "    files_data['eeg_layout_file'] = eeg_layout\n",
    "    files_data['signals_file'] = signal_info_file\n",
    "    \n",
    "    return files_data\n",
    "    \n",
    "#\n",
    "the_bids_collection = o.get_collection('/MATERIALS/NRMD/NRMD_RAWD_BIDS')\n",
    "for mode in raw_modes:\n",
    "    print(f\"looking for raw data mode: {mode}\")\n",
    "    # get the main samples collection\n",
    "    the_raw_collection = o.get_collection(f'/MATERIALS/NRMD/NRMD_RAWD_{mode}')\n",
    "    the_raw_samples = the_raw_collection.get_samples()\n",
    "    # get the recording samples\n",
    "    for raw_sample in the_raw_samples:\n",
    "        \n",
    "        raw_parents = o.get_object(raw_sample.permId).parents\n",
    "        #print(sample.code)\n",
    "        sample_code = raw_sample.code.split('_')\n",
    "        '''\n",
    "        try:\n",
    "        '''\n",
    "\n",
    "        # check if the session is a valid one and not one of SXXX, SYYY, ...\n",
    "        try:\n",
    "            int(sample_code[5][1:])\n",
    "        except  Exception as e:\n",
    "            print(f\"   - session invalid: {e}\")\n",
    "            continue\n",
    "\n",
    "        # get or create the raw bids samples collection\n",
    "        try:\n",
    "            the_stim_sample = o.get_sample(f'/MATERIALS/NRMD/NRMD_RAWD_STIM_{sample_code[3]}_{sample_code[4]}_{sample_code[5]}')\n",
    "            print(f\"   - found corresponding stimulation sample: {the_stim_sample.code}\")\n",
    "        except  Exception as e:\n",
    "            print(f\"   - stimulation sample {the_stim_sample.code} not found. Skipping...\")\n",
    "            print(f\"   - error: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            the_bids_sample = o.get_sample(f'/MATERIALS/NRMD/NRMD_RAWD_BIDS_{sample_code[3]}_{sample_code[4]}_{sample_code[5]}')\n",
    "            print(f\"   - getting existing data recording mode: {the_bids_sample.code}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            the_bids_sample = o.new_sample(type = 'DATA_RECORDING_MODE',\n",
    "                                           code = f'NRMD_RAWD_BIDS_{sample_code[3]}_{sample_code[4]}_{sample_code[5]}',\n",
    "                                           project = raw_sample.project,\n",
    "                                           space = 'MATERIALS',\n",
    "                                           collection = f'/MATERIALS/NRMD/{the_bids_collection.code}',\n",
    "                                           props = {'data_recording_mode.data_recording_mode':raw_sample.props()['data_recording_mode.data_recording_mode'],\n",
    "                                                    'data_recording_mode.session': raw_sample.props()['data_recording_mode.session'],\n",
    "                                                    'data_recording_mode.phase': raw_sample.props()['data_recording_mode.phase'],\n",
    "                                                    'data_recording_mode.participant': raw_sample.props()['data_recording_mode.participant'],\n",
    "                                                   },\n",
    "                                            )\n",
    "            the_bids_sample.save()\n",
    "            the_bids_sample.parents = raw_parents + [raw_sample,the_stim_sample]\n",
    "            the_bids_sample.save()\n",
    "            print(f\"   - getting newly created data recording mode: {the_bids_sample.code}\")\n",
    "\n",
    "\n",
    "        download_path = os.path.join(bids_path,f\"{sample_code[3]}_{sample_code[4]}_{sample_code[5]}\")\n",
    "        proj_par = [_p for _p in raw_parents if o.get_object(_p).type == 'PROJECT'][0]\n",
    "        sensor_par = [_p for _p in raw_parents if o.get_object(_p).type == 'SENSOR'][0]\n",
    "        stim_par = [_p for _p in raw_parents if o.get_object(_p).type == 'STIM'][0]\n",
    "        participant_par = [_p for _p in raw_parents if o.get_object(_p).type == 'PARTICIPANT'][0]\n",
    "        print(f\"   - raw data download path: {download_path}\")\n",
    "        \n",
    "        # check if bids dataset already exists for the task\n",
    "        if len(list(the_bids_sample.get_datasets())) == 0:\n",
    "            # get raw datasets to format\n",
    "            try:\n",
    "                infos = getRawFilesAndData(raw_sample,the_stim_sample,download_path)\n",
    "            except Exception as e:\n",
    "                print(f\"   - raw data error: {e}\")\n",
    "                continue\n",
    "            # create bids files by task\n",
    "            events_dict = {'save_path': bids_path,\n",
    "                           'stim_csv_file': infos['stim_file'],\n",
    "                           'signals_file': infos['signals_file'],\n",
    "                           'raw_eeg_file': infos['eeg_file'],\n",
    "                           'photodiode_file':infos['photodiode_file'],\n",
    "                           'eeg_layout_file': infos['eeg_layout_file'],\n",
    "                           'participant_id': sample_code[3],\n",
    "                           'project_phase': sample_code[4],\n",
    "                           'session_id': sample_code[5],\n",
    "                           'task_name': o.get_object(stim_par).props('stim.name'),\n",
    "                           'project_infos': o.get_object(proj_par).props(),\n",
    "                           'acquisition_infos': o.get_object(sensor_par).props(), \n",
    "                           'stim_infos': o.get_object(stim_par).props()\n",
    "                          }\n",
    "            print(f\"   - events dict: {events_dict}\")\n",
    "            #if the_bids_sample.get_datasets()[0].props('rawd_bids.name')!= events_dict['task_name']:\n",
    "\n",
    "            # all bids files to create the dataset\n",
    "            bids_files = createBidsFiles(events_dict,participant_par)\n",
    "            # create dataset for bids files\n",
    "            createBidsDataset(the_bids_sample,bids_files,events_dict)\n",
    "            # remove downloaded files\n",
    "            shutil.rmtree(bids_path) #bids_path\n",
    "            print(f\"   - files removed from: {download_path}\")\n",
    "            \n",
    "            #else:\n",
    "            #    print(f\"   - task dataset already exists. Skipping...\")\n",
    "        else: \n",
    "            print(f\"   - task dataset already exists. Skipping...\")\n",
    "        '''\n",
    "        except Exception as e:\n",
    "            print (f\"Error: {e}\")\n",
    "            print(f\"   - session {raw_sample.code} not valid. Skipping...\")\n",
    "        '''\n",
    "\n",
    "print(\"DONE\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
